{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ***EMOTION DETECTOR FROM GIVEN TEXT***  \n",
    "\n",
    "+ Uses ML Model  \n",
    "+ Uses sklearn  \n",
    "+ Dataset from internet  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the training dataset into the program  \n",
    "+ Function read_data() used to return the data from data set from the txt file  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 7480\n"
     ]
    }
   ],
   "source": [
    "def read_data(file):\n",
    "    data = []\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
    "            text = line[line.find(\"]\")+1:].strip()\n",
    "            data.append([label, text])\n",
    "    return data\n",
    "\n",
    "file = 'text.txt'\n",
    "data = read_data(file)\n",
    "print(f\"Number of instances: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation and feature generation\n",
    "* function ngram() is used to tokenise the given text  \n",
    "    >Tokenisation is a process in which the raw data is broken into small chunks so that the ML model is easily able to analyse the data.  \n",
    "* function create_feature() is used to do a feature generation from the existing data  \n",
    "    >Feature generation is an important feature to build our ML Model as it enables to get new refined data from existing one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(token, n): \n",
    "    output = []\n",
    "    for i in range(n-1, len(token)): \n",
    "        ngram = ' '.join(token[i-n+1:i+1])\n",
    "        output.append(ngram) \n",
    "    return output\n",
    "\n",
    "def create_feature(text, nrange=(1, 1)):\n",
    "    text_features = [] \n",
    "    text = text.lower() \n",
    "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
    "    for n in range(nrange[0], nrange[1]+1): \n",
    "        text_features += ngram(text_alphanum.split(), n)    \n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    text_features += ngram(text_punc.split(), 1)\n",
    "    return Counter(text_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create list containing the emotions and the labels  \n",
    "##### ***Emotions are***  \n",
    "- **Joy**  \n",
    "- **Anger**\n",
    "- **Fear**\n",
    "- **Sadness**  \n",
    "- **Disgust**  \n",
    "- **Shame**\n",
    "- **Guilt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(item, name): \n",
    "    items = list(map(float, item.split()))\n",
    "    label = \"\"\n",
    "    for idx in range(len(items)): \n",
    "        if items[idx] == 1: \n",
    "            label += name[idx] + \" \"\n",
    "    \n",
    "    return label.strip()\n",
    "\n",
    "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "\n",
    "xAll = []\n",
    "yAll = []\n",
    "for label, text in data:\n",
    "    yAll.append(convert_label(label, emotions))\n",
    "    xAll.append(create_feature(text, nrange=(1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data to test set and trainig set.  \n",
    ">This will be useful for us to make our model more efficient.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(xAll, yAll, test_size = 0.2, random_state = 123)\n",
    "\n",
    "def train_test(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "    return train_acc, test_acc\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse = True)\n",
    "xTrain = vectorizer.fit_transform(xTrain)\n",
    "xTest = vectorizer.transform(xTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the ML Model  \n",
    "+ Here we use 4 types of classifier model based on ML and we use the one with the best accuracy  \n",
    "    - ***SVC*** \\- stands for Support Vector Classification. It is a very useful classification model based     on supervised machine learning. It comes under the Support Vector Machines.  \n",
    "    - ***LSVC*** \\- stands for Linear Support Vector Classification. It also comes under Support Vector Machines. Another supervised machine learning algorithm.  \n",
    "    - ***Random Forest Classifier*** \\- It is a meta estimator which fits a lot of decision tree classifiers on sub samples of the data set and uses averaging to imporve its result.  \n",
    "    - ***Decision Tree Classifier*** \\- It is a classsifier which converts the given data into the form of decision trees which can be interpreted as a set of rules and can be used to classsify test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Classifier                | Training Accuracy | Test Accuracy |\n",
      "| ------------------------- | ----------------- | ------------- |\n",
      "| SVC                       |         0.9067513 |     0.4512032 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| LinearSVC                 |         0.9988302 |     0.5768717 |\n",
      "| RandomForestClassifier    |         0.9988302 |     0.5541444 |\n",
      "| DecisionTreeClassifier    |         0.9988302 |     0.4632353 |\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "lsvc = LinearSVC(random_state=123)\n",
    "rforest = RandomForestClassifier(random_state=123)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "clifs = [svc, lsvc, rforest, dtree]\n",
    "\n",
    "# train and test them \n",
    "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
    "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
    "for clf in clifs: \n",
    "    clf_name = clf.__class__.__name__\n",
    "    train_acc, test_acc = train_test(clf, xTrain, xTest, yTrain, yTest)\n",
    "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting the emotions\n",
    ">We now assign the labels in our data set to the emotions and print the output to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy       (1. 0. 0. 0. 0. 0. 0.)  1084\n",
      "anger     (0. 0. 1. 0. 0. 0. 0.)  1080\n",
      "sadness   (0. 0. 0. 1. 0. 0. 0.)  1079\n",
      "fear      (0. 1. 0. 0. 0. 0. 0.)  1078\n",
      "disgust   (0. 0. 0. 0. 1. 0. 0.)  1057\n",
      "guilt     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
      "shame     (0. 0. 0. 0. 0. 1. 0.)  1045\n"
     ]
    }
   ],
   "source": [
    "emo = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "emo.sort()\n",
    "label_freq = {}\n",
    "for label, _ in data: \n",
    "    label_freq[label] = label_freq.get(label, 0) + 1\n",
    "\n",
    "# print the labels and their counts in sorted order \n",
    "for l in sorted(label_freq, key=label_freq.get, reverse=True):\n",
    "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### ***Finally we use some text to see the emotions. This can be predefined text or user input which afterwards detects the emotions based on our model and gives output***\n",
    "\n",
    ">Here we take a paragraph as input from user and make our model analyse each sentence. This will enable us to understand the dominant emotion in the user and give advice based on the emotion that is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So you are mainly composed with Happines!!\n",
      "\n",
      "Here is some advice for you!!!\n",
      "It is nice that you are happy and cheerful.\n",
      "Keep going the same way and dont lose hope!!\n"
     ]
    }
   ],
   "source": [
    "#emoji_dict = {\"joy\":\"😂\", \"fear\":\"😱\", \"anger\":\"😠\", \"sadness\":\"😢\", \"disgust\":\"😒\", \"shame\":\"😳\", \"guilt\":\"😳\"}\n",
    "user_input = input(\"Enter whatever sentences you feel! Please use '.' after each sentence.\")\n",
    "\n",
    "user_emo=[]\n",
    "texts = user_input.split(\".\")\n",
    "for l in range(0,len(texts)):\n",
    "    texts[l] = texts[l].strip()\n",
    "for text in texts: \n",
    "    features = create_feature(text, nrange=(1, 4))\n",
    "    features = vectorizer.transform(features)\n",
    "    prediction = clf.predict(features)[0]\n",
    "    #print(text,emoji_dict[prediction])\n",
    "    user_emo.append(prediction)\n",
    "dom_emo_dic = dict(Counter(user_emo))\n",
    "max = 0\n",
    "dom_emo = list(dom_emo_dic.keys())[0]\n",
    "for keys in dom_emo_dic:\n",
    "    if(dom_emo_dic[keys]>max):\n",
    "        max,dom_emo=dom_emo_dic[keys],keys\n",
    "emotional_text={\"joy\":\"Happines\", \"fear\":\"Fear\", \"anger\":\"Anger\", \"sadness\":\"Sadness\", \"disgust\":\"Disgust\", \"shame\":\"Shamefullness\", \"guilt\":\"Guilty\"}\n",
    "emotional_advice = {'joy':\"It is nice that you are happy and cheerful.\\nKeep going the same way and dont lose hope!!\",\n",
    "                    'sadness':\"Don't be sad. Being sad wont solve anything.\\nFind the cause of that sadness and fight it to be happy.\\nEnjoy Life and be happy.!\",\n",
    "                    'fear':\"Fear is absolutely normal.\\nBut staying afraid isn't nice.\\nHence break out of that shell and face your fear.\\nTake help from a close friend and overcome it!!!.\",\n",
    "                    'anger':\"Anger is a dangerous emotion!\\nNever give into anger.\\nMeditate and let go of it.\\nRevenge and anger is never the solution to anything.\\nLet go of that emotion!!\",\n",
    "                    'disgust':\"Feeling disgust about something?\\nMake it into something else.\\nBeing disgusted will only make you hate it more.\\nHence let it go and be calm.\",\n",
    "                    'shame':\"Shameful about somethin you did?\\nIt is natural. But dont stay that way.\\nDo something to make it right.\\nIt'll make you more happy and less shamefull.\",\n",
    "                    'guilt':\"Guilty?\\nIt is not good.\\nBeing in guilt will ruin yuor life.\\nTry to get rid of it as soon as possible and make ammends.\\nThat is the only way to move forward.\"}\n",
    "print(f\"So you are mainly composed with {emotional_text[dom_emo]}!!\\n\")\n",
    "print(\"Here is some advice for you!!!\")\n",
    "print(emotional_advice[dom_emo])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca585555a2867b459a38eaf8b2b47956aef7a6f770e52f1f5dfa1f8f05e57688"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
